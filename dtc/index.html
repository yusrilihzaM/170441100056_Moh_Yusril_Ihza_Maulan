



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Tugas Kuliah Data Mining">
      
      
        <link rel="canonical" href="https:///yusrilx02/170441100056_Moh_Yusril_Ihza_Maulana.github.io/dtc/">
      
      
        <meta name="author" content="Moh Yusril Ihza Maulana">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Decision Tree Classifier - Data Mining</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#pengertian-decision-tree-classification" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https:///yusrilx02/170441100056_Moh_Yusril_Ihza_Maulana.github.io" title="Data Mining" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Data Mining
            </span>
            <span class="md-header-nav__topic">
              Decision Tree Classifier
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/yusrilx02/170441100056_Moh_Yusril_Ihza_Maulana" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    170441100056_Moh_Yusril_Ihza_Maulana
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Identitas Penulis" class="md-tabs__link md-tabs__link--active">
        Identitas Penulis
      </a>
    
  </li>

      
        
      
        
      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https:///yusrilx02/170441100056_Moh_Yusril_Ihza_Maulana.github.io" title="Data Mining" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Data Mining
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/yusrilx02/170441100056_Moh_Yusril_Ihza_Maulana" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    170441100056_Moh_Yusril_Ihza_Maulana
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Identitas Penulis" class="md-nav__link">
      Identitas Penulis
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../kmean/" title="K-Means Clustering" class="md-nav__link">
      K-Means Clustering
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../knn/" title="K-Nearest Neighbor" class="md-nav__link">
      K-Nearest Neighbor
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Decision Tree Classifier
      </label>
    
    <a href="./" title="Decision Tree Classifier" class="md-nav__link md-nav__link--active">
      Decision Tree Classifier
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pengertian-decision-tree-classification" title="Pengertian Decision Tree Classification" class="md-nav__link">
    Pengertian Decision Tree Classification
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jenis-decision-tree" title="Jenis Decision Tree" class="md-nav__link">
    Jenis Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#terminologi-penting-terkait-dengan-decision-tree-classification" title="Terminologi Penting terkait dengan Decision Tree Classification" class="md-nav__link">
    Terminologi Penting terkait dengan Decision Tree Classification
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kelebihan-dan-kekurangan-decision-tree-classification" title="Kelebihan dan Kekurangan Decision Tree Classification" class="md-nav__link">
    Kelebihan dan Kekurangan Decision Tree Classification
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kelebihan" title="Kelebihan:" class="md-nav__link">
    Kelebihan:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kekurangan" title="Kekurangan:" class="md-nav__link">
    Kekurangan:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algoritma-decision-tree-classification" title="Algoritma Decision Tree Classification" class="md-nav__link">
    Algoritma Decision Tree Classification
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#id3" title="ID3" class="md-nav__link">
    ID3
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#entropy" title="Entropy" class="md-nav__link">
    Entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-gain" title="Information Gain" class="md-nav__link">
    Information Gain
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gini-index" title="Gini Index" class="md-nav__link">
    Gini Index
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rumus-gini-index" title="Rumus Gini Index" class="md-nav__link">
    Rumus Gini Index
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-untuk-menghitung-gini-untuk-pemisahan" title="Langkah-langkah untuk Menghitung Gini untuk pemisahan" class="md-nav__link">
    Langkah-langkah untuk Menghitung Gini untuk pemisahan
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementasi-decision-tree-classification-breast-cancer-wisconsin-diagnostic-dataset" title="Implementasi Decision Tree Classification Breast Cancer Wisconsin (Diagnostic) Dataset" class="md-nav__link">
    Implementasi Decision Tree Classification Breast Cancer Wisconsin (Diagnostic) Dataset
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kebutuhan-software" title="Kebutuhan Software" class="md-nav__link">
    Kebutuhan Software
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#library-python-yang-digunakan" title="Library Python yang digunakan:" class="md-nav__link">
    Library Python yang digunakan:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#import-library-yang-dibutuhkan" title="Import Library yang dibutuhkan" class="md-nav__link">
    Import Library yang dibutuhkan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memuat-dataset" title="Memuat Dataset" class="md-nav__link">
    Memuat Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-preprocessing" title="Data Preprocessing" class="md-nav__link">
    Data Preprocessing
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#menampilkan-5-data-teratas" title="Menampilkan 5 Data teratas" class="md-nav__link">
    Menampilkan 5 Data teratas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#menampilkan-ringkasan-dataset-serta-menghilangkan-kolom-yang-tidak-berguna" title="Menampilkan ringkasan dataset serta menghilangkan kolom yang tidak berguna" class="md-nav__link">
    Menampilkan ringkasan dataset serta menghilangkan kolom yang tidak berguna
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mengganti-class-m-dan-b-menjadi-0-dan-1" title="Mengganti class M dan B menjadi 0 dan 1" class="md-nav__link">
    Mengganti class M dan B menjadi 0 dan 1
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#membagi-data-30-sebagai-data-testing-dan-70-sebagai-data-training" title="Membagi data 30% sebagai data testing dan 70% sebagai data training" class="md-nav__link">
    Membagi data 30% sebagai data testing dan 70% sebagai data training
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#membuat-variabel-independen-dan-responsible" title="Membuat variabel independen dan responsible" class="md-nav__link">
    Membuat variabel independen dan responsible
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seleksi-fitur-untuk-visualisasi-decision-tree" title="Seleksi Fitur untuk visualisasi Decision tree" class="md-nav__link">
    Seleksi Fitur untuk visualisasi Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree-classifier-dengan-criterion-information-gain" title="Decision Tree Classifier dengan criterion information gain" class="md-nav__link">
    Decision Tree Classifier dengan criterion information gain
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visualisasi-decision-tree-dengan-criterion-information-gain" title="Visualisasi Decision Tree dengan criterion information gain" class="md-nav__link">
    Visualisasi Decision Tree dengan criterion information gain
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree-classifier-dengan-criterion-gini-index" title="Decision Tree Classifier dengan criterion gini index" class="md-nav__link">
    Decision Tree Classifier dengan criterion gini index
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visualisasi-decision-tree-dengan-criterion-gini-index" title="Visualisasi Decision Tree dengan criterion gini index" class="md-nav__link">
    Visualisasi Decision Tree dengan criterion gini index
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#menampilkan-hasil-prediksi-data-testing" title="Menampilkan Hasil Prediksi Data testing" class="md-nav__link">
    Menampilkan Hasil Prediksi Data testing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referensi" title="Referensi" class="md-nav__link">
    Referensi
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pengertian-decision-tree-classification" title="Pengertian Decision Tree Classification" class="md-nav__link">
    Pengertian Decision Tree Classification
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#jenis-decision-tree" title="Jenis Decision Tree" class="md-nav__link">
    Jenis Decision Tree
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#terminologi-penting-terkait-dengan-decision-tree-classification" title="Terminologi Penting terkait dengan Decision Tree Classification" class="md-nav__link">
    Terminologi Penting terkait dengan Decision Tree Classification
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#kelebihan-dan-kekurangan-decision-tree-classification" title="Kelebihan dan Kekurangan Decision Tree Classification" class="md-nav__link">
    Kelebihan dan Kekurangan Decision Tree Classification
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kelebihan" title="Kelebihan:" class="md-nav__link">
    Kelebihan:
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kekurangan" title="Kekurangan:" class="md-nav__link">
    Kekurangan:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algoritma-decision-tree-classification" title="Algoritma Decision Tree Classification" class="md-nav__link">
    Algoritma Decision Tree Classification
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#id3" title="ID3" class="md-nav__link">
    ID3
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#entropy" title="Entropy" class="md-nav__link">
    Entropy
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#information-gain" title="Information Gain" class="md-nav__link">
    Information Gain
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gini-index" title="Gini Index" class="md-nav__link">
    Gini Index
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rumus-gini-index" title="Rumus Gini Index" class="md-nav__link">
    Rumus Gini Index
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-untuk-menghitung-gini-untuk-pemisahan" title="Langkah-langkah untuk Menghitung Gini untuk pemisahan" class="md-nav__link">
    Langkah-langkah untuk Menghitung Gini untuk pemisahan
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementasi-decision-tree-classification-breast-cancer-wisconsin-diagnostic-dataset" title="Implementasi Decision Tree Classification Breast Cancer Wisconsin (Diagnostic) Dataset" class="md-nav__link">
    Implementasi Decision Tree Classification Breast Cancer Wisconsin (Diagnostic) Dataset
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kebutuhan-software" title="Kebutuhan Software" class="md-nav__link">
    Kebutuhan Software
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#library-python-yang-digunakan" title="Library Python yang digunakan:" class="md-nav__link">
    Library Python yang digunakan:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#import-library-yang-dibutuhkan" title="Import Library yang dibutuhkan" class="md-nav__link">
    Import Library yang dibutuhkan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#memuat-dataset" title="Memuat Dataset" class="md-nav__link">
    Memuat Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-preprocessing" title="Data Preprocessing" class="md-nav__link">
    Data Preprocessing
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#menampilkan-5-data-teratas" title="Menampilkan 5 Data teratas" class="md-nav__link">
    Menampilkan 5 Data teratas
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#menampilkan-ringkasan-dataset-serta-menghilangkan-kolom-yang-tidak-berguna" title="Menampilkan ringkasan dataset serta menghilangkan kolom yang tidak berguna" class="md-nav__link">
    Menampilkan ringkasan dataset serta menghilangkan kolom yang tidak berguna
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mengganti-class-m-dan-b-menjadi-0-dan-1" title="Mengganti class M dan B menjadi 0 dan 1" class="md-nav__link">
    Mengganti class M dan B menjadi 0 dan 1
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#membagi-data-30-sebagai-data-testing-dan-70-sebagai-data-training" title="Membagi data 30% sebagai data testing dan 70% sebagai data training" class="md-nav__link">
    Membagi data 30% sebagai data testing dan 70% sebagai data training
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#membuat-variabel-independen-dan-responsible" title="Membuat variabel independen dan responsible" class="md-nav__link">
    Membuat variabel independen dan responsible
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#seleksi-fitur-untuk-visualisasi-decision-tree" title="Seleksi Fitur untuk visualisasi Decision tree" class="md-nav__link">
    Seleksi Fitur untuk visualisasi Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree-classifier-dengan-criterion-information-gain" title="Decision Tree Classifier dengan criterion information gain" class="md-nav__link">
    Decision Tree Classifier dengan criterion information gain
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visualisasi-decision-tree-dengan-criterion-information-gain" title="Visualisasi Decision Tree dengan criterion information gain" class="md-nav__link">
    Visualisasi Decision Tree dengan criterion information gain
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree-classifier-dengan-criterion-gini-index" title="Decision Tree Classifier dengan criterion gini index" class="md-nav__link">
    Decision Tree Classifier dengan criterion gini index
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#visualisasi-decision-tree-dengan-criterion-gini-index" title="Visualisasi Decision Tree dengan criterion gini index" class="md-nav__link">
    Visualisasi Decision Tree dengan criterion gini index
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#menampilkan-hasil-prediksi-data-testing" title="Menampilkan Hasil Prediksi Data testing" class="md-nav__link">
    Menampilkan Hasil Prediksi Data testing
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#referensi" title="Referensi" class="md-nav__link">
    Referensi
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Decision Tree Classifier</h1>
                
                <h2 id="pengertian-decision-tree-classification"><strong>Pengertian Decision Tree Classification</strong><a class="headerlink" href="#pengertian-decision-tree-classification" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../assets/images/DTC.jpg" /></p>
<p><em>Decision tree</em> merupakan suatu metode klasifikasi yang menggunakan struktur pohon, dimana setiap <em>node</em> merepresentasikan atribut dan cabangnya merepresentasikan nilai dari atribut, sedangkan daunnya digunakan untuk merepresentasikan kelas. <em>Node</em> teratas dari <em>decision tree</em> ini disebut dengan <em>root</em>.</p>
<p>Ini memecah dataset menjadi himpunan bagian yang lebih kecil dengan peningkatan kedalaman pohon. Hasil akhirnya adalah pohon dengan simpul keputusan dan simpul daun. Node keputusan (mis., Outlook) memiliki dua atau lebih cabang (mis., Sunny, Overcast, dan Rainy). Node daun (mis., Play) mewakili klasifikasi atau keputusan. Node keputusan teratas dalam pohon yang sesuai dengan prediktor terbaik disebut simpul akar. Pohon keputusan dapat menangani data kategorikal dan numerik.</p>
<p><img alt="" src="../assets/images/dss_!.png" /></p>
<h2 id="jenis-decision-tree"><strong>Jenis Decision Tree</strong><a class="headerlink" href="#jenis-decision-tree" title="Permanent link">&para;</a></h2>
<ul>
<li>Categorical Variable Decision Tree (Pohon Keputusan Variabel Kategorikal) merupakan pohon keputusan yang memiliki variabel target kategorikal </li>
<li>Continuous Variable Decision Tree()  merupakan Decision Tree yang memiliki variabel target kontinu </li>
</ul>
<h2 id="terminologi-penting-terkait-dengan-decision-tree-classification"><strong>Terminologi Penting terkait dengan Decision Tree Classification</strong><a class="headerlink" href="#terminologi-penting-terkait-dengan-decision-tree-classification" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../assets/images/dss_2.png" /></p>
<ol>
<li><strong>Root Node</strong>: Ini mewakili seluruh populasi atau sampel dan ini selanjutnya dibagi menjadi dua atau lebih set homogen.</li>
<li><strong>Splitting</strong>: Ini adalah proses membagi sebuah node menjadi dua atau lebih sub-node.</li>
<li><strong>Decision Node</strong>: Ketika sebuah sub-node terbagi menjadi beberapa sub-node, maka itu disebut simpul keputusan (decision node).</li>
<li><strong>Leaf/ Terminal Node</strong>: Node tanpa anak (tanpa pemisahan lebih lanjut) disebut Leaf atau Terminal node.</li>
<li><strong>Pruning</strong>: Ketika kita mengurangi ukuran pohon keputusan dengan menghapus node (kebalikan dari Splitting), proses ini disebut pemangkasan (pruning).</li>
<li><strong>Branch / Sub-Tree</strong>: Subbagian pohon keputusan disebut cabang (Branch) atau sub-pohon.( Sub-Tree)</li>
<li><strong>Parent and Child Node</strong>: Sebuah node, yang dibagi menjadi beberapa sub-node disebut parent node dari sub-node dimana sebagai sub-node adalah anak dari node induk</li>
</ol>
<h2 id="kelebihan-dan-kekurangan-decision-tree-classification"><strong>Kelebihan dan Kekurangan Decision Tree Classification</strong><a class="headerlink" href="#kelebihan-dan-kekurangan-decision-tree-classification" title="Permanent link">&para;</a></h2>
<h3 id="kelebihan">Kelebihan:<a class="headerlink" href="#kelebihan" title="Permanent link">&para;</a></h3>
<ol>
<li>Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik.</li>
<li>Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu.</li>
<li>Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional</li>
<li>Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan.</li>
</ol>
<h3 id="kekurangan">Kekurangan:<a class="headerlink" href="#kekurangan" title="Permanent link">&para;</a></h3>
<ol>
<li>Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan.</li>
<li>Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar.</li>
<li>Kesulitan dalam mendesain pohon keputusan yang optimal.</li>
<li>Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.</li>
</ol>
<h2 id="algoritma-decision-tree-classification"><strong>Algoritma Decision Tree Classification</strong><a class="headerlink" href="#algoritma-decision-tree-classification" title="Permanent link">&para;</a></h2>
<ol>
<li>ID3</li>
<li>Gini Index</li>
<li>Chi-Square</li>
<li>Reduction in Variance</li>
</ol>
<p>Namun disini kita hanya membahan ID3 dan Gini index saja.</p>
<h3 id="id3"><strong>ID3</strong><a class="headerlink" href="#id3" title="Permanent link">&para;</a></h3>
<p>Algoritma inti untuk membangun pohon keputusan disebut ID3. Dikembangkan oleh J. R. Quinlan, algoritma ini menggunakan pencarian top-down,  melalui ruang cabang yang mungkin tanpa backtracking. ID3 menggunakan <strong>Entropy</strong> dan <strong>Information Gain</strong> untuk membuat keputusan</p>
<h4 id="entropy"><strong>Entropy</strong><a class="headerlink" href="#entropy" title="Permanent link">&para;</a></h4>
<p>Pohon keputusan dibangun dari atas ke bawah dari simpul akar (root node) dan melibatkan mempartisi data menjadi subset yang berisi instance dengan nilai yang sama (homogen). Algoritma ID3 menggunakan entropi untuk menghitung homogenitas sampel. Jika sampel benar-benar homogen, entropinya nol dan jika sampel dibagi rata maka entropinya satu.</p>
<p><img alt="" src="../assets/images/dss_3.png" /></p>
<p>Untuk membangun pohon keputusan, kita perlu menghitung dua jenis entropi menggunakan tabel frekuensi sebagai berikut:</p>
<p>a. Entropy menggunakan tabel frekuensi satu atribut:</p>
<p><img alt="" src="../assets/images/dss_4.png" /></p>
<p>b. Entropi menggunakan tabel frekuensi dua atribut:</p>
<p><img alt="" src="../assets/images/dss_5.png" /></p>
<h4 id="information-gain">Information Gain<a class="headerlink" href="#information-gain" title="Permanent link">&para;</a></h4>
<p>Information Gain didasarkan pada penurunan entropi setelah kumpulan data dibagi pada atribut. Membangun pohon keputusan adalah tentang menemukan atribut yang mengembalikan perolehan informasi tertinggi (mis., Cabang yang paling homogen).</p>
<p><strong>Langkah 1</strong>: Hitung entropi target.</p>
<p><img alt="" src="../assets/images/dss_6.png" /></p>
<p><strong>Langkah 2</strong>: Kumpulan data kemudian dibagi pada atribut yang berbeda. Entropi untuk setiap cabang dihitung. Kemudian ditambahkan secara proporsional, untuk mendapatkan total entropi untuk pemisahan. Entropi yang dihasilkan dikurangi dari entropi sebelum pemisahan. Hasilnya adalah Information Gain, atau penurunan entropi.</p>
<p><img alt="" src="../assets/images/dss_7.png" /></p>
<p><strong>Langkah 3</strong>: Pilih atribut dengan perolehan Information Gain terbesar sebagai simpul keputusan (decision node), bagi dataset dengan cabang-cabangnya dan ulangi proses yang sama pada setiap cabang.</p>
<p><img alt="" src="../assets/images/dss_8.png" /></p>
<p><img alt="" src="../assets/images/dss_9.png" /></p>
<p><strong>Langkah 4a</strong>: Cabang dengan entropi 0 adalah simpul daun.</p>
<p><img alt="" src="../assets/images/dss_10.png" /></p>
<p><strong>Langkah 4b</strong>: Cabang dengan entropi lebih dari 0 membutuhkan pemisahan lebih lanjut</p>
<p><img alt="" src="../assets/images/dss_11.png" /></p>
<p><strong>Langkah 5</strong>: Algoritma ID3 dijalankan secara rekursif pada cabang-cabang non-daun, sampai semua data diklasifikasikan.</p>
<h3 id="gini-index"><strong>Gini Index</strong><a class="headerlink" href="#gini-index" title="Permanent link">&para;</a></h3>
<p>Indeks Gini mengatakan, jika kita memilih dua item dari populasi secara acak maka mereka harus dari kelas yang sama dan probabilitas untuk ini adalah 1 jika populasi murni.</p>
<ol>
<li>Ia bekerja dengan variabel target kategori "Sukses" atau "Kegagalan".</li>
<li>Ini hanya melakukan split Biner</li>
<li>Semakin tinggi nilai Gini semakin tinggi homogenitasnya.</li>
<li>CART (Klasifikasi dan Pohon Regresi) menggunakan metode Gini untuk membuat pemisahan biner.</li>
</ol>
<h4 id="rumus-gini-index"><strong>Rumus Gini Index</strong><a class="headerlink" href="#rumus-gini-index" title="Permanent link">&para;</a></h4>
<p><img alt="" src="../assets/images/gini1.webp" /></p>
<p>pi adalah probabilitas bahwa sebuah tuple dalam D milik kelas Ci.</p>
<p>Weighted Gini untuk Pemisahan:</p>
<p><img alt="" src="../assets/images/gini2.webp" /></p>
<h4 id="langkah-langkah-untuk-menghitung-gini-untuk-pemisahan"><strong>Langkah-langkah untuk Menghitung Gini untuk pemisahan</strong><a class="headerlink" href="#langkah-langkah-untuk-menghitung-gini-untuk-pemisahan" title="Permanent link">&para;</a></h4>
<ol>
<li>Hitung Gini untuk sub-node, menggunakan rumus jumlah kuadrat probabilitas untuk keberhasilan dan kegagalan (p² + q²).</li>
<li>Hitung Gini untuk split menggunakan skor Gini tertimbang dari setiap node dari split itu</li>
</ol>
<p>Contoh: - Mengacu pada contoh di mana kami ingin memisahkan siswa berdasarkan variabel target (playing criket atau tidak). Dalam snapshot di bawah ini, kami membagi populasi menggunakan dua variabel input Gender dan Class. Sekarang, saya ingin mengidentifikasi split mana yang menghasilkan lebih banyak sub-node homogen menggunakan indeks Gini.</p>
<p><img alt="" src="../assets/images/dss_12.png" /></p>
<p>Pemisahan di gender</p>
<ol>
<li>Gini untuk sub node Female = (0.43)x(0.43)+(0.57)x(0.57)=0.51</li>
<li>Gini untuk sub node Male = (0.56)x(0.56)+(0.44)x(0.44)=0.51</li>
<li>Weighted Gini untuk Pemisahan Gender  = (10/30)x0.68+(20/30)x0.55 = <strong>0.59</strong></li>
</ol>
<p>Pemisahan di class</p>
<ol>
<li>Gini untuk sub node Class IX= (0.2)x(0.2)+(0.8)x(0.8)=0.68</li>
<li>Gini untuk sub node Class X= (0.65)x(0.65)+(0.35)x(0.35)=0.55</li>
<li>
<p>Weighted Gini untuk Pemisahan Class  =  (14/30)x0.51+(16/30)x0.51 = <strong>0.51</strong></p>
</li>
<li></li>
</ol>
<h2 id="implementasi-decision-tree-classification-breast-cancer-wisconsin-diagnostic-dataset"><strong>Implementasi Decision Tree Classification Breast Cancer Wisconsin (Diagnostic) Dataset</strong><a class="headerlink" href="#implementasi-decision-tree-classification-breast-cancer-wisconsin-diagnostic-dataset" title="Permanent link">&para;</a></h2>
<h3 id="kebutuhan-software"><strong>Kebutuhan Software</strong><a class="headerlink" href="#kebutuhan-software" title="Permanent link">&para;</a></h3>
<ol>
<li>Python 3.0 atau versi yang lebih baru, disini saya menggunakan python 3.7</li>
<li>IDE Pycharm</li>
<li>Jupyter notebook</li>
</ol>
<h4 id="library-python-yang-digunakan"><strong>Library Python yang digunakan:</strong><a class="headerlink" href="#library-python-yang-digunakan" title="Permanent link">&para;</a></h4>
<ul>
<li>Pandas</li>
</ul>
<p>pandas adalah sebuah librari berlisensi BSD dan open source yang menyediakan struktur data dan analisis data yang mudah digunakan dan berkinerja tinggi untuk bahasa pemrograman Python.</p>
<p>instal pandas:</p>
<pre class="codehilite"><code>pip install pandas</code></pre>

<ul>
<li>Scikit Learn </li>
</ul>
<p>Machine learning ada yang berbasis statistika ada juga yang tidak. Salah satunya adalah support vector machine dan regresi linier. Mungkin bagi sebagian orang sudah biasa menulis sendiri library untuk implementasi kedua algoritma tadi. Tapi untuk membuatnya dalam waktu singkat tentu butuh waktu yang tidak sedikit pula.</p>
<p>Scikit-Learn memberikan sejumlah fitur untuk keperluan data science seperti:</p>
<ul>
<li>Algoritma Regresi</li>
<li>Algoritma Naive Bayes</li>
<li>Algoritma Clustering</li>
<li>Algoritma Decision Tree</li>
<li>Parameter Tuning</li>
<li>Data Preprocessing Tool</li>
<li>Export / Import Model</li>
<li>Machine learning pipeline
    dan lainnya</li>
</ul>
<p>instal Scikit Learn :</p>
<pre class="codehilite"><code>pip install scikit-learn</code></pre>

<ul>
<li>graphviz</li>
</ul>
<p>kitadapat menggunakan fungsi Scikit-learn export_graphviz untuk menampilkan pohon di dalam notebook Jupyter. Untuk merencanakan pohon, Anda juga perlu menginstal graphviz dan pydotplus</p>
<p>instal menggunakan pip:</p>
<pre class="codehilite"><code>pip install graphviz</code></pre>

<p>Instal menggunakan conda:</p>
<pre class="codehilite"><code>conda install -c conda-forge graphviz</code></pre>

<ul>
<li>pydotplus</li>
</ul>
<p>PyDotPlus adalah versi perbaikan dari proyek pydot lama yang menyediakan Antarmuka Python ke bahasa Dot Graphviz</p>
<pre class="codehilite"><code>pip install pydotplus</code></pre>

<p>Instal menggunakan conda:</p>
<pre class="codehilite"><code>conda install -c conda-forge pydotplus </code></pre>

<h3 id="import-library-yang-dibutuhkan"><strong>Import Library yang dibutuhkan</strong><a class="headerlink" href="#import-library-yang-dibutuhkan" title="Permanent link">&para;</a></h3>
<pre class="codehilite"><code class="language-python">import pandas as pd 
from sklearn.model_selection import train_test_split
from sklearn import metrics #importing modul metrik
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
from sklearn.externals.six import StringIO  
from IPython.display import Image  
import pydotplus</code></pre>

<h3 id="memuat-dataset"><strong>Memuat Dataset</strong><a class="headerlink" href="#memuat-dataset" title="Permanent link">&para;</a></h3>
<p>Mengimport dataset yang digunakan untuk pengimplemtasian K-Nearest Neighbor</p>
<p>dataset bisa didownload <a href="https://github.com/yusrilx02/KNN-Breast-Cancer-Wisconsin-Diagnostic-DataSet/tree/master/dataset">disini</a> atau langsung dari kaggle <a href="https://github.com/yusrilx02/KNN-Breast-Cancer-Wisconsin-Diagnostic-DataSet/tree/master/dataset">disini</a></p>
<pre class="codehilite"><code class="language-python"># Memuat dataset
data = pd.read_csv("E:\Semester 4\data mining/bc.csv",encoding = "ISO-8859-1")</code></pre>

<h3 id="data-preprocessing"><strong>Data Preprocessing</strong><a class="headerlink" href="#data-preprocessing" title="Permanent link">&para;</a></h3>
<h4 id="menampilkan-5-data-teratas">Menampilkan 5 Data teratas<a class="headerlink" href="#menampilkan-5-data-teratas" title="Permanent link">&para;</a></h4>
<p>Menampilkan jumlah masing-masing diagnosis dan kolom diagnosis digunakan sebagai class nantinya.</p>
<pre class="codehilite"><code>data.head(5)</code></pre>

<p>Output:</p>
<p><img alt="" src="../assets/images/knn_i1.PNG" /></p>
<h4 id="menampilkan-ringkasan-dataset-serta-menghilangkan-kolom-yang-tidak-berguna">Menampilkan ringkasan dataset serta menghilangkan kolom yang tidak berguna<a class="headerlink" href="#menampilkan-ringkasan-dataset-serta-menghilangkan-kolom-yang-tidak-berguna" title="Permanent link">&para;</a></h4>
<pre class="codehilite"><code># ringkasan dataset
data.info()</code></pre>

<p>Output:</p>
<pre class="codehilite"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 569 entries, 0 to 568
Data columns (total 33 columns):
id                         569 non-null int64
diagnosis                  569 non-null object
radius_mean                569 non-null float64
texture_mean               569 non-null float64
perimeter_mean             569 non-null float64
area_mean                  569 non-null float64
smoothness_mean            569 non-null float64
compactness_mean           569 non-null float64
concavity_mean             569 non-null float64
concave points_mean        569 non-null float64
symmetry_mean              569 non-null float64
fractal_dimension_mean     569 non-null float64
radius_se                  569 non-null float64
texture_se                 569 non-null float64
perimeter_se               569 non-null float64
area_se                    569 non-null float64
smoothness_se              569 non-null float64
compactness_se             569 non-null float64
concavity_se               569 non-null float64
concave points_se          569 non-null float64
symmetry_se                569 non-null float64
fractal_dimension_se       569 non-null float64
radius_worst               569 non-null float64
texture_worst              569 non-null float64
perimeter_worst            569 non-null float64
area_worst                 569 non-null float64
smoothness_worst           569 non-null float64
compactness_worst          569 non-null float64
concavity_worst            569 non-null float64
concave points_worst       569 non-null float64
symmetry_worst             569 non-null float64
fractal_dimension_worst    569 non-null float64
Unnamed: 32                0 non-null float64
dtypes: float64(31), int64(1), object(1)
memory usage: 146.8+ KB</code></pre>

<p>bisa dilihat dari hasil output diatas ada kolom yang tidak bernama ("Unnamed") akan kita hilangkan, serta menghilangkan kolom yang tidak berguna yaitu kolom ()"id") :</p>
<pre class="codehilite"><code class="language-python">#menghapus kolom yang tidak berguna
#menghapus kolom "id"
data.drop("id",axis=1,inplace=True)
#menghapus the "Unnamed: 32" column
data.drop("Unnamed: 32",axis=1,inplace=True) </code></pre>

<pre class="codehilite"><code class="language-python">#hasil
data.info()</code></pre>

<p>Output:</p>
<p>bisa dilihat kolom "id" dan kolom yang tidak mempunyai nama "unnamed" telah hilang</p>
<pre class="codehilite"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 569 entries, 0 to 568
Data columns (total 31 columns):
diagnosis                  569 non-null object
radius_mean                569 non-null float64
texture_mean               569 non-null float64
perimeter_mean             569 non-null float64
area_mean                  569 non-null float64
smoothness_mean            569 non-null float64
compactness_mean           569 non-null float64
concavity_mean             569 non-null float64
concave points_mean        569 non-null float64
symmetry_mean              569 non-null float64
fractal_dimension_mean     569 non-null float64
radius_se                  569 non-null float64
texture_se                 569 non-null float64
perimeter_se               569 non-null float64
area_se                    569 non-null float64
smoothness_se              569 non-null float64
compactness_se             569 non-null float64
concavity_se               569 non-null float64
concave points_se          569 non-null float64
symmetry_se                569 non-null float64
fractal_dimension_se       569 non-null float64
radius_worst               569 non-null float64
texture_worst              569 non-null float64
perimeter_worst            569 non-null float64
area_worst                 569 non-null float64
smoothness_worst           569 non-null float64
compactness_worst          569 non-null float64
concavity_worst            569 non-null float64
concave points_worst       569 non-null float64
symmetry_worst             569 non-null float64
fractal_dimension_worst    569 non-null float64
dtypes: float64(30), object(1)
memory usage: 137.9+ KB</code></pre>

<p>Kemudian kita lihat lagi kolom beserta 5 data pertama:</p>
<pre class="codehilite"><code class="language-python"># 5 baris pertama
data.head(5)
</code></pre>

<p>Output:</p>
<p><img alt="" src="../assets/images/knn_i4.PNG" /></p>
<h4 id="mengganti-class-m-dan-b-menjadi-0-dan-1">Mengganti class M dan B menjadi 0 dan 1<a class="headerlink" href="#mengganti-class-m-dan-b-menjadi-0-dan-1" title="Permanent link">&para;</a></h4>
<p>diagnosis adalah variabel yang bertanggung jawab untuk klasifikasi
disini kita mengganti M dan B masing-masing dengan 1 dan 0 </p>
<pre class="codehilite"><code class="language-python">#diagnosis adalah variabel yang bertanggung jawab untuk klasifikasi
#mengganti M dan B masing-masing dengan 1 dan 0
data.diagnosis=data.diagnosis.map({'M':1,'B':0})</code></pre>

<p>Kemudian kita hitung berapa banyak jumlah masing- masing feature</p>
<pre class="codehilite"><code class="language-python">#menghitung variabel diagnosis
data.diagnosis.value_counts()</code></pre>

<p>output:</p>
<pre class="codehilite"><code>0    357
1    212
Name: diagnosis, dtype: int64</code></pre>

<h4 id="membagi-data-30-sebagai-data-testing-dan-70-sebagai-data-training">Membagi data 30% sebagai data testing dan 70% sebagai data training<a class="headerlink" href="#membagi-data-30-sebagai-data-testing-dan-70-sebagai-data-training" title="Permanent link">&para;</a></h4>
<pre class="codehilite"><code class="language-python"># preprocessing dataset selesai 
#splitting dataset ke training dan testing
train, test = train_test_split(data, test_size = 0.3,random_state=1234)</code></pre>

<pre class="codehilite"><code class="language-python">#mencari hasil
print(train.shape)
print(test.shape)</code></pre>

<pre class="codehilite"><code>(398, 31)
(171, 31)</code></pre>

<h3 id="membuat-variabel-independen-dan-responsible"><strong>Membuat variabel independen dan responsible</strong><a class="headerlink" href="#membuat-variabel-independen-dan-responsible" title="Permanent link">&para;</a></h3>
<p>variabel independen dan responsible nantinya akan digunakan dalam proses prediksi</p>
<p>variable independen mengambil dari semua kolom dan variable responsible  dari diagnosis</p>
<pre class="codehilite"><code class="language-python">#membuat variabel independen untuk training
train_X = train.iloc[:, 1:31]
#membuat variabel responsible untuk training
train_y=train.diagnosis
#membuat variabel independen untuk testing
test_X= test.iloc[:, 1:31]
#membuat variabel responsible untuk ttesting
test_y =test.diagnosis</code></pre>

<p>kita cek dulu berapa jumlahnya</p>
<pre class="codehilite"><code class="language-python">#mencari hasil
print(train_X.shape)
print(train_y.shape)
print(test_X.shape)
print(test_y.shape)</code></pre>

<p>output:</p>
<pre class="codehilite"><code>(398, 30)
(398,)
(171, 30)
(171,)</code></pre>

<h3 id="seleksi-fitur-untuk-visualisasi-decision-tree"><strong>Seleksi Fitur untuk visualisasi Decision tree</strong><a class="headerlink" href="#seleksi-fitur-untuk-visualisasi-decision-tree" title="Permanent link">&para;</a></h3>
<p>dilangkah atas sudah ada seleksi fitur untuk perhitungan decision tree , dilangkah ini seleksi fitur digunakan untuk melengkapi komponen visualisasi decision tree yang dilangkah selanjutnya</p>
<pre class="codehilite"><code>feature_cols = ["radius_mean","texture_mean","perimeter_mean","area_mean","smoothness_mean","compactness_mean","concavity_mean","concave points_mean","symmetry_mean","fractal_dimension_mean","radius_se","texture_se","perimeter_se","area_se","smoothness_se","compactness_se","concavity_se","concave points_se","symmetry_se","fractal_dimension_se","radius_worst","texture_worst","perimeter_worst","area_worst","smoothness_worst","compactness_worst","concavity_worst","concave points_worst","symmetry_worst","fractal_dimension_worst",]
X = data[feature_cols] # mengambil Features
y = data.diagnosis # Target variable</code></pre>

<h3 id="decision-tree-classifier-dengan-criterion-information-gain"><strong>Decision Tree Classifier dengan criterion information gain</strong><a class="headerlink" href="#decision-tree-classifier-dengan-criterion-information-gain" title="Permanent link">&para;</a></h3>
<pre class="codehilite"><code>model_entropy= DecisionTreeClassifier(criterion="entropy",random_state=1234)
#learning
model_entropy.fit(train_X,train_y)
#Prediksi
prediction_entropy=model_entropy.predict(test_X)
#mengevaluasi(Accuracy)
print("Accuracy:",metrics.accuracy_score(prediction,test_y))
#evaluation(Confusion Metrix)
print("Confusion Metrix:\n",metrics.confusion_matrix(prediction,test_y))</code></pre>

<p>Output:</p>
<pre class="codehilite"><code>Accuracy: 0.9298245614035088
Confusion Metrix:
 [[99  6]
 [ 6 60]]</code></pre>

<h4 id="visualisasi-decision-tree-dengan-criterion-information-gain"><strong>Visualisasi Decision Tree dengan criterion information gain</strong><a class="headerlink" href="#visualisasi-decision-tree-dengan-criterion-information-gain" title="Permanent link">&para;</a></h4>
<pre class="codehilite"><code>dot_data = StringIO()
export_graphviz(model_entropy, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['M','L'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('entropy.png')
Image(graph.create_png())</code></pre>

<p>Output:</p>
<p><img alt="" src="../assets/images/output_13_0.png" /></p>
<h3 id="decision-tree-classifier-dengan-criterion-gini-index"><strong>Decision Tree Classifier dengan criterion gini index</strong><a class="headerlink" href="#decision-tree-classifier-dengan-criterion-gini-index" title="Permanent link">&para;</a></h3>
<pre class="codehilite"><code>model_gini= DecisionTreeClassifier(criterion="gini",random_state=1234)
#learning
model_gini.fit(train_X,train_y)
#Prediksi
prediction_gini=model_gini.predict(test_X)
#mengevaluasi(Accuracy)
print("Accuracy:",metrics.accuracy_score(prediction,test_y))
#evaluation(Confusion Metrix)
print("Confusion Metrix:\n",metrics.confusion_matrix(prediction,test_y))</code></pre>

<p>Output:</p>
<pre class="codehilite"><code>Accuracy: 0.9298245614035088
Confusion Metrix:
 [[99  6]
 [ 6 60]]</code></pre>

<h4 id="visualisasi-decision-tree-dengan-criterion-gini-index"><strong>Visualisasi Decision Tree dengan criterion gini index</strong><a class="headerlink" href="#visualisasi-decision-tree-dengan-criterion-gini-index" title="Permanent link">&para;</a></h4>
<pre class="codehilite"><code>dot_data = StringIO()
export_graphviz(model_gini, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['M','L'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('gini.png')
Image(graph.create_png())</code></pre>

<p>Output:</p>
<p><img alt="" src="../assets/images/output_15_0.png" /></p>
<h3 id="menampilkan-hasil-prediksi-data-testing"><strong>Menampilkan Hasil Prediksi Data testing</strong><a class="headerlink" href="#menampilkan-hasil-prediksi-data-testing" title="Permanent link">&para;</a></h3>
<p>Pada langkah ini kita menampilkan hasil prediksi dari data testing dan hasil prediksi menggunakan information gain dan gini index.</p>
<p>menampilan semua feature datates dan hasil prediksi menggunakan information gain dan gini index.</p>
<pre class="codehilite"><code>datatest=pd.DataFrame(test_X)
datatest['diagnosis']=test_y
datatest['hasil prediksi entropy']=prediction_entropy
datatest['hasil prediksi gini']=prediction_gini
print(datatest)</code></pre>

<p>Output:</p>
<p><img alt="" src="../assets/images/1.PNG" /></p>
<p>selajutnya kita akan mensederhanakan agar lebih enak dilihat dengan hanya menampilkan diagnosis, dan hasil prediksi menggunakan information gain dan gini index.</p>
<pre class="codehilite"><code>final=pd.DataFrame({"diagnosis":test_y,"hasil prediksi entropy":prediction_entropy,"hasil prediksi gini":prediction_gini})
print(final)</code></pre>

<p>Output:</p>
<pre class="codehilite"><code> diagnosis  hasil prediksi entropy  hasil prediksi gini
531          0                       0                    0
166          0                       0                    0
485          0                       0                    0
66           0                       0                    0
220          0                       0                    0
356          0                       0                    0
414          1                       1                    1
525          0                       0                    0
77           1                       1                    1
239          1                       1                    1
254          1                       1                    1
447          0                       0                    0
301          0                       0                    0
133          0                       0                    0
187          0                       0                    0
78           1                       1                    1
319          0                       0                    0
412          0                       0                    0
349          0                       0                    0
11           1                       1                    1
240          0                       0                    0
29           1                       1                    1
302          1                       1                    1
521          1                       1                    1
373          1                       1                    1
481          0                       0                    0
100          1                       1                    1
304          0                       0                    0
159          0                       0                    0
360          0                       0                    1
..         ...                     ...                  ...
202          1                       1                    1
435          1                       1                    1
375          0                       0                    0
47           1                       1                    0
497          0                       0                    0
13           1                       1                    1
221          0                       0                    0
22           1                       1                    1
255          1                       0                    1
109          0                       0                    0
348          0                       0                    0
129          1                       1                    1
152          0                       1                    0
67           0                       0                    0
213          1                       1                    1
495          0                       0                    1
517          1                       1                    1
219          1                       1                    1
290          0                       0                    0
488          0                       0                    0
309          0                       0                    0
6            1                       1                    1
405          0                       0                    0
452          0                       0                    0
54           1                       1                    1
305          0                       0                    0
560          0                       1                    1
285          0                       0                    0
355          0                       0                    0
329          1                       1                    1

[171 rows x 3 columns]
</code></pre>

<p><strong>Untuk notebook bisa dilihat <a href="https://colab.research.google.com/drive/1hPE9O0pqF3gAcgG_qmkzVQdO3bMsB40r">disini</a> atau bisa diunduh <a href="https://github.com/yusrilx02/Decision-Tree-Classification-Breast-Cancer-Wisconsin-Diagnostic-Dataset">disini</a></strong></p>
<h2 id="referensi"><strong>Referensi</strong><a class="headerlink" href="#referensi" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Mayu Shinohara. 2017., Hyper Parameters Tuning of DTree,RF,SVM,kNN di <a href="https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn">https://www.kaggle.com/mayu0116/hyper-parameters-tuning-of-dtree-rf-svm-knn</a></p>
</li>
<li>
<p>sklearn.tree.DecisionTreeClassifier. di <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</a></p>
</li>
<li>
<p>Avinash Navlani. 2018. ,Decision Tree Classification in Python  di <a href="https://www.datacamp.com/community/tutorials/decision-tree-classification-python">https://www.datacamp.com/community/tutorials/decision-tree-classification-python</a></p>
</li>
<li>
<p>Dafni Sidiropoulou Velidou., 2018. Interactive Visualization of Decision Trees with Jupyter Widgets di <a href="https://towardsdatascience.com/interactive-visualization-of-decision-trees-with-jupyter-widgets-ca15dd312084">https://towardsdatascience.com/interactive-visualization-of-decision-trees-with-jupyter-widgets-ca15dd312084</a></p>
</li>
<li>
<p>Rishabh Jain.,  2017.  Decision Tree. It begins here. di <a href="https://medium.com/@rishabhjain_22692/decision-trees-it-begins-here-93ff54ef134">https://medium.com/@rishabhjain_22692/decision-trees-it-begins-here-93ff54ef134</a></p>
</li>
<li>
<p>Decision Tree - Classification di<a href="https://www.saedsayad.com/decision_tree.htm">https://www.saedsayad.com/decision_tree.htm</a></p>
</li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../knn/" title="K-Nearest Neighbor" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                K-Nearest Neighbor
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 Moh Yusril Ihza Maulana
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>